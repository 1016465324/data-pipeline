local.test=true

database.type=mongo

#parallelism must set 1 when read database mongo
flink.parallelism=1

flink.checkpoint.path=file:///tmp/flink/
flink.checkpoint.interval=5000
flink.checkpoint.timeout=5000

#指定接受消息的topic
kafka.target.topic=test
kafka.target.topic.partition=1

#kafka config
#指定broker的地址清单，地址的格式为host：port
bootstrap.servers=localhost:9092
#指定了必须要有多少个分区副本收到消息，生产者才会认为写入消息是成功的，这个参数对消息丢失的可能性有重大影响。
acks=all
#指定生产者可以重发消息的次数。
retries=10
#当多个消息被发送同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。当批次内存被填满后，批次里的所有消息会被发送出去。
batch.size=16384
#指定了生产者在发送批次前等待更多消息加入批次的时间。
linger.ms=10
#设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。
buffer.memory=33554432
#消息的超时时间
request.timeout.ms=60000
#key序列化类型
key.serializer=org.apache.kafka.common.serialization.StringSerializer
#value序列化类型
value.serializer=org.apache.kafka.common.serialization.StringSerializer

#kerberos的配置
kerberos=false
java.security.auth.login.config=./kafka_client_jaas.conf
java.security.krb5.conf=./krb5.conf
security.protocol=SASL_PLAINTEXT
sasl.mechanism=GSSAPI
sasl.kerberos.service.name=kafka